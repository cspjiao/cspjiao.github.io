
@misc{darban_deep_2022,
	title = {Deep {Learning} for {Time} {Series} {Anomaly} {Detection}: {A} {Survey}},
	shorttitle = {Deep {Learning} for {Time} {Series} {Anomaly} {Detection}},
	url = {http://arxiv.org/abs/2211.05244},
	abstract = {Time series anomaly detection has applications in a wide range of research fields and applications, including manufacturing and healthcare. The presence of anomalies can indicate novel or unexpected events, such as production faults, system defects, or heart fluttering, and is therefore of particular interest. The large size and complex patterns of time series have led researchers to develop specialised deep learning models for detecting anomalous patterns. This survey focuses on providing structured and comprehensive state-of-the-art time series anomaly detection models through the use of deep learning. It providing a taxonomy based on the factors that divide anomaly detection models into different categories. Aside from describing the basic anomaly detection technique for each category, the advantages and limitations are also discussed. Furthermore, this study includes examples of deep anomaly detection in time series across various application domains in recent years. It finally summarises open issues in research and challenges faced while adopting deep anomaly detection models.},
	language = {en},
	urldate = {2023-09-15},
	publisher = {arXiv},
	author = {Darban, Zahra Zamanzadeh and Webb, Geoffrey I. and Pan, Shirui and Aggarwal, Charu C. and Salehi, Mahsa},
	month = dec,
	year = {2022},
	note = {arXiv:2211.05244 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Darban 等 - 2022 - Deep Learning for Time Series Anomaly Detection A.pdf:files/29/Darban 等 - 2022 - Deep Learning for Time Series Anomaly Detection A.pdf:application/pdf},
}

@misc{fan_debiasing_2022,
	title = {Debiasing {Graph} {Neural} {Networks} via {Learning} {Disentangled} {Causal} {Substructure}},
	url = {http://arxiv.org/abs/2209.14107},
	doi = {10.48550/arXiv.2209.14107},
	abstract = {Most Graph Neural Networks (GNNs) predict the labels of unseen graphs by learning the correlation between the input graphs and labels. However, by presenting a graph classification investigation on the training graphs with severe bias, surprisingly, we discover that GNNs always tend to explore the spurious correlations to make decision, even if the causal correlation always exists. This implies that existing GNNs trained on such biased datasets will suffer from poor generalization capability. By analyzing this problem in a causal view, we find that disentangling and decorrelating the causal and bias latent variables from the biased graphs are both crucial for debiasing. Inspiring by this, we propose a general disentangled GNN framework to learn the causal substructure and bias substructure, respectively. Particularly, we design a parameterized edge mask generator to explicitly split the input graph into causal and bias subgraphs. Then two GNN modules supervised by causal/bias-aware loss functions respectively are trained to encode causal and bias subgraphs into their corresponding representations. With the disentangled representations, we synthesize the counterfactual unbiased training samples to further decorrelate causal and bias variables. Moreover, to better benchmark the severe bias problem, we construct three new graph datasets, which have controllable bias degrees and are easier to visualize and explain. Experimental results well demonstrate that our approach achieves superior generalization performance over existing baselines. Furthermore, owing to the learned edge mask, the proposed model has appealing interpretability and transferability. Code and data are available at: https://github.com/googlebaba/DisC.},
	urldate = {2023-10-05},
	publisher = {arXiv},
	author = {Fan, Shaohua and Wang, Xiao and Mo, Yanhu and Shi, Chuan and Tang, Jian},
	month = sep,
	year = {2022},
	note = {arXiv:2209.14107 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, 去偏差图神经网络},
	file = {arXiv Fulltext PDF:files/70/Fan 等 - 2022 - Debiasing Graph Neural Networks via Learning Disen.pdf:application/pdf},
}
